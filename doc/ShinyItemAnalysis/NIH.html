<!DOCTYPE html><html><head><title>R: NIH grant peer review scoring dataset</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R.css" />
</head><body><div class="container">

<table style="width: 100%;"><tr><td>NIH</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2>NIH grant peer review scoring dataset</h2>

<h3>Description</h3>

<p>The <code>NIH</code> dataset (Erosheva et al., 2020a) was sampled from
a full set of 54,740 R01 applications submitted by black and white
principal investigators (PIs) and reviewed by NIH's Center for Scientific
Review (CSR) during council years 2014&ndash;2016.
</p>
<p>It contains the original random sample of white applicants as generated by
Erosheva et al. (2020b) and a sample of 46 black applicants generated to
obtain the same ratio of white and black applicants as in the original
sample (for details, see Erosheva et al., 2021a). The dataset was used by
Erosheva et al. (2021b) to demonstrate issues of inter-rater reliability in
case of restricted samples.
</p>
<p>The available variables include preliminary criterion scores on
Significance, Investigator, Innovation, Approach, Environment and a
preliminary Overall Impact Score. Each of these criteria and the overall
score is scored on an integer scale from 1 (best) to 9 (worst). Besides the
preliminary criteria and Overall Impact Scores, the data include applicant
race, the structural covariates (PI ID, application ID, reviewer ID,
administering institute, IRG, and SRG), the matching variables &ndash; gender,
ethnicity (Hispanic/Latino or not), career stage, type of academic degree,
institution prestige (as reflected by the NIH funding bin), area of science
(as reflected by the IRG handling the application), application type (new
or renewal) and status (amended or not) &ndash; as well as the final overall
score. In addition, the file includes a study group ID variable that refers
to the Matched and Random subsets used in the original study.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(NIH)
</code></pre>


<h3>Format</h3>

<p><code>NIH</code> is a <code>data.frame</code> consisting of 5802 observations on
27 variables.
</p>

<dl>
<dt>ID</dt><dd><p>Proposal ID. </p>
</dd>
<dt>Score</dt><dd><p>Preliminary Overall Impact score (1-9 integer scale, 1 best). </p>
</dd>
<dt>Significance, Investigator, Innovation, Approach, Environment </dt><dd>
<p>Preliminary Criterion Scores (1-9 integer scale, 1 best). </p>
</dd>
<dt>PIRace</dt><dd><p>Principal investigator's self-identified race; <code>"White"</code>
or <code>"Black"</code>. </p>
</dd>
<dt>PIID</dt><dd><p>Anonymized ID of principal investigator (PI). </p>
</dd>
<dt>PIGender</dt><dd><p>PI's gender membership; <code>"Male"</code> or <code>"Female"</code>. </p>
</dd>
<dt>PIEthn</dt><dd><p>PI's ethnicity; <code>"Hispanic/Latino"</code> or <code>"Non-Hispanic"</code>. </p>
</dd>
<dt>PICareerStage</dt><dd><p>PI's career stage; <code>"ESI"</code> Early Stage Investigator,
<code>"Experienced"</code> Experienced Investigator, or <code>"Non-ES NI"</code>
Non-Early Stage New Investigator. </p>
</dd>
<dt>PIDegree</dt><dd><p>PI's degree; <code>"PhD"</code>, <code>"MD"</code>, <code>"MD/PhD"</code>,
or <code>"Others"</code>. </p>
</dd>
<dt>PIInst</dt><dd><p>Lead PI's institution's FY 2014 total institution NIH funding;
5 bins with 1 being most-funded.</p>
</dd>
<dt>GroupID</dt><dd><p>Group ID. </p>
</dd>
<dt>RevID</dt><dd><p>Reviewer's ID. </p>
</dd>
<dt>IRG</dt><dd><p>IRG (Integrated Research Group) id. </p>
</dd>
<dt>AdminOrg</dt><dd><p>Administering Organization id. </p>
</dd>
<dt>SRG</dt><dd><p>SRG (Scientific Research Group) id. </p>
</dd>
<dt>PropType</dt><dd><p>Application type, <code>"New"</code> or <code>"Renewal"</code>. </p>
</dd>
<dt>Ammend</dt><dd><p>Ammend. Logical. </p>
</dd>
<dt>ScoreAvg</dt><dd><p>Average of the three overall scores from different reviewers. </p>
</dd>
<dt>ScoreAvgAdj</dt><dd><p>Average of the three overall scores from different reviewers, increased by multiple of 0.001 of the worst score. </p>
</dd>
<dt>ScoreRank</dt><dd><p>Project rank calculated based on <code>ScoreAvg</code>. </p>
</dd>
<dt>ScoreRankAdj</dt><dd><p>Project rank calculated based on <code>ScoreAvgAdj</code>. </p>
</dd>
<dt>ScoreFinalChar</dt><dd><p>Final Overall Impact score (1-9 integer scale, 1 best; <code>"ND"</code>
refers to &quot;not discussed&quot;)</p>
</dd>
<dt>ScoreFinal</dt><dd><p>Final Overall Impact score (1-9 integer scale, 1 best). </p>
</dd>
</dl>



<h3>References</h3>

<p>Erosheva, E. A., Grant, S., Chen, M.-C., Lindner, M. D., Nakamura, R. K., &amp;
Lee, C. J. (2020a). NIH peer review: Criterion scores completely account for
racial disparities in overall impact scores. Science Advances 6(23), eaaz4868,
doi: <a href="https://doi.org/10.1126/sciadv.aaz4868">10.1126/sciadv.aaz4868</a>
</p>
<p>Erosheva, E. A., Grant, S., Chen, M.-C., Lindner, M. D., Nakamura, R. K., &amp;
Lee, C. J. (2020b). Supplementary material: NIH peer review: Criterion scores
completely account for racial disparities in overall impact scores.
Science Advances 6(23), eaaz4868, doi: <a href="https://doi.org/10.17605/OSF.IO/4D6RX">10.17605/OSF.IO/4D6RX</a>
</p>
<p>Erosheva, E., Martinkova, P., &amp; Lee, C. J. (2021a). Supplementary material:
When zero may not be zero: A cautionary note on the use of inter-rater
reliability in evaluating grant peer review.
</p>
<p>Erosheva, E., Martinkova, P., &amp; Lee, C. J. (2021b). When zero may not be zero: A
cautionary note on the use of inter-rater reliability in evaluating grant
peer review. Journal of the Royal Statistical Society &ndash; Series A. Accepted.
</p>


<h3>See Also</h3>

<p><code>ICCrestricted()</code>
</p>


</div>
</body></html>
